import { StreamingTextResponse } from "ai";
import { NextRequest } from "next/server";

// ‚úÖ Este runtime lo puedes dejar (o quitar si no usas edge)
export const runtime = "edge";

export async function POST(req: NextRequest) {
  try {
    const { messages } = await req.json();

    const lastMessage =
      messages?.at(-1)?.content || "Hola, ¬øen qu√© puedo ayudarte?";
    const simulatedReply = `ü§ñ Respuesta simulada: "${lastMessage}" (sin OpenAI).`;

    const encoder = new TextEncoder();
    const stream = new ReadableStream({
      start(controller) {
        controller.enqueue(encoder.encode(simulatedReply));
        controller.close();
      },
    });

    return new StreamingTextResponse(stream);
  } catch (error) {
    console.error("‚ùå ERROR en /api/chat:", error);
    return new Response("Error interno del servidor", { status: 500 });
  }
}
// //edge:"Ejecutar tu c√≥digo en el servidor m√°s cercano al usuario (cliente), para que la respuesta sea m√°s r√°pida."
// // streaming datos enviados en tiempo real por partes
// //El streaming de datos es un proceso en el que los datos se env√≠an y procesan de forma continua
